# -*- coding: utf-8 -*-
"""Copy of caption_segmentation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kLPdn0or1eiPmhnF7Am8hX2xk6ELz1Jp
"""
import os

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

import srt

import asr
import caption

# map de woorden naar indices
def prepare_sequence(seq, to_ix):
    idxs = [to_ix.get(w, 0) for w in seq]
    return torch.tensor(idxs, dtype=torch.long)


# Preprocessing:
# Hier voegen we de tag <eoc> (End-Of-Caption) toe aan het einde van de caption groepen
# (+ meer preprocessing steps ..)

def create_traindata(directory):
    training_data = []
    for entry in os.scandir(directory):
        filename = entry.path
        with open(filename) as subs:
            training_data = []
            for sub in list(srt.parse(subs)):
                sub.content += " <eoc>"
                sub.content = sub.content.replace('\n', ' <nl> ')
                sub.content = sub.content.replace('.', ' .')
                sub.content = sub.content.replace('?', ' ?')
                sub.content = sub.content.replace('!', ' !')
                sub.content = sub.content.replace(',', ' ,')
                sub.content = sub.content.replace(';', ' ;')
                sub.content = sub.content.replace(':', ' :')
                training_data.append(sub.content.lower().split())

    return training_data

def create_testdata(training_data, groups):
    max_len = max([len(x) for x in training_data])

    test_set = [word.text for word in groups]
    eval_data = []
    for i in range(len(test_set) // max_len):
        eval_data.append(test_set[i*max_len:i*max_len+max_len])


    eval_data.append(test_set[(i+1)*max_len:(i+1)*max_len+len(test_set)%max_len])

    return eval_data


class LSTMCaption(nn.Module):

    def __init__(self, embedding_dim, hidden_dim, vocab_size):
        super(LSTMCaption, self).__init__()
        self.hidden_dim = hidden_dim

        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)

        # The LSTM takes word embeddings as inputs, and outputs hidden states
        # with dimensionality hidden_dim.
        self.lstm = nn.LSTM(embedding_dim, hidden_dim)

        # The linear layer that maps from hidden state space to vocabulary space
        self.hidden2output = nn.Linear(hidden_dim, vocab_size)

    def forward(self, sentence):
        embeds = self.word_embeddings(sentence)
        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))
        output_space = self.hidden2output(lstm_out.view(len(sentence), -1))
        output_scores = F.log_softmax(output_space, dim=1)
        return output_scores


def train(n_epochs, training_data):
    for epoch in range(n_epochs):

        # Go once over the entire train data
        for sentence in training_data:
            # Step 1. Remember that Pytorch accumulates gradients.
            # We need to clear them out before each instance
            model.zero_grad()

            # Step 2. Get our inputs ready for the network, that is, turn them into
            # Tensors of word indices.
            sentence_in = prepare_sequence(sentence, word_to_ix)
            # targets = prepare_sequence(tags, tag_to_ix)

            # Step 3. Run our forward pass.
            output_scores = model(sentence_in)

            pad_idx = len(sentence)

            # Step 4. Compute the loss, gradients, and update the parameters by
            #  calling optimizer.step()
            loss = loss_function(output_scores[:pad_idx, :], sentence_in[:pad_idx])
            loss.backward()
            optimizer.step()

directory = r'../dataset/srt/'
training_data = create_traindata(directory)
path = '../asr/sample01.asrOutput.json'

groups = asr.ASR(path).groups()
eval_data = create_testdata(training_data, groups)

# Maak een index set van de geobserveerde woorden
word_to_ix = {'unk': 0}
for sent in training_data:
    for word in sent:
        if word not in word_to_ix:
            word_to_ix[word] = len(word_to_ix)

# maak een map terug van de index set naar de woorden
ix_to_word = {v:k for (k, v) in word_to_ix.items()}

EMBEDDING_DIM = 64
HIDDEN_DIM = 64

model = LSTMCaption(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix))
loss_function = nn.NLLLoss()
optimizer = optim.SGD(model.parameters(), lr=0.1)


train(5, training_data)
with torch.no_grad():
    ix = 0
    optimized_groups = []
    caption_group = []

    for sentence in eval_data:
        inputs = prepare_sequence(sentence, word_to_ix)
        output_scores = model(inputs)

        indices = torch.argmax(output_scores, axis=1)
        modeled = [ix_to_word[index.item()] for index in indices]

        for model_word, word in zip(modeled, groups[ix:]):
            if model_word == '<eoc>':
                optimized_groups.append(caption_group)
                caption_group = []

            else:
                caption_group.append(word)

            ix += 1

    optimized_groups.append(caption_group)
    caption.write(optimized_groups, 'lstm_output.srt')
